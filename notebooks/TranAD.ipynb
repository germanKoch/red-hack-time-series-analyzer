{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc2PAixdYXU7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import math\n",
        "# import dgl\n",
        "# from dgl.nn import GATConv\n",
        "from time import time\n",
        "from torch.nn import TransformerEncoder\n",
        "from torch.nn import TransformerDecoder\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVUdW4ic6FYj"
      },
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkJryO7D98oy"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9js7uLE3-m9L"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model).float() * (-math.log(10000.0) / d_model))\n",
        "        pe += torch.sin(position * div_term)\n",
        "        pe += torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x, pos=0):\n",
        "        x = x + self.pe[pos:pos+x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDbjPXz1-rXs"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=16, dropout=0):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = nn.LeakyReLU(True)\n",
        "\n",
        "    def forward(self, src,src_mask=None, src_key_padding_mask=None, is_causal=True):\n",
        "        src2 = self.self_attn(src, src, src)[0]\n",
        "        src = src + self.dropout1(src2)\n",
        "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        return src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETw4K4FK-t18"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=16, dropout=0):\n",
        "        super(TransformerDecoderLayer, self).__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = nn.LeakyReLU(True)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            tgt,\n",
        "            memory,\n",
        "            tgt_mask=None,\n",
        "            memory_mask=None,\n",
        "            tgt_key_padding_mask=None,\n",
        "            memory_key_padding_mask=None,\n",
        "            tgt_is_causal=True,\n",
        "            memory_is_causal=True\n",
        "        ):\n",
        "        tgt2 = self.self_attn(tgt, tgt, tgt)[0]\n",
        "        tgt = tgt + self.dropout1(tgt2)\n",
        "        tgt2 = self.multihead_attn(tgt, memory, memory)[0]\n",
        "        tgt = tgt + self.dropout2(tgt2)\n",
        "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
        "        tgt = tgt + self.dropout3(tgt2)\n",
        "        return tgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prYgeSCW9-DK"
      },
      "outputs": [],
      "source": [
        "class TranAD(nn.Module):\n",
        "    def __init__(self, feats, lr, batch_size, window_size):\n",
        "        super(TranAD, self).__init__()\n",
        "        self.name = 'TranAD'\n",
        "        self.lr = lr\n",
        "        self.batch = batch_size\n",
        "        self.n_feats = feats\n",
        "        self.n_window = window_size\n",
        "        self.n = self.n_feats * self.n_window\n",
        "        self.pos_encoder = PositionalEncoding(2 * feats, 0.1, self.n_window)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model=2 * feats, nhead=feats, dim_feedforward=16, dropout=0.1)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, 1)\n",
        "        decoder_layers1 = TransformerDecoderLayer(d_model=2 * feats, nhead=feats, dim_feedforward=16, dropout=0.1)\n",
        "        self.transformer_decoder1 = TransformerDecoder(decoder_layers1, 1)\n",
        "        decoder_layers2 = TransformerDecoderLayer(d_model=2 * feats, nhead=feats, dim_feedforward=16, dropout=0.1)\n",
        "        self.transformer_decoder2 = TransformerDecoder(decoder_layers2, 1)\n",
        "        self.fcn = nn.Sequential(nn.Linear(2 * feats, feats), nn.Sigmoid())\n",
        "        self.double()\n",
        "\n",
        "    def encode(self, src, c, tgt):\n",
        "        src = torch.cat((src, c), dim=2)\n",
        "        src = src * math.sqrt(self.n_feats)\n",
        "        src = self.pos_encoder(src)\n",
        "        memory = self.transformer_encoder(src)\n",
        "        tgt = tgt.repeat(1, 1, 2)\n",
        "        return tgt, memory\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        # Phase 1 - Without anomaly scores\n",
        "        c = torch.zeros_like(src)\n",
        "        x1 = self.fcn(self.transformer_decoder1(*self.encode(src, c, tgt)))\n",
        "        # Phase 2 - With anomaly scores\n",
        "        c = (x1 - src) ** 2\n",
        "        x2 = self.fcn(self.transformer_decoder2(*self.encode(src, c, tgt)))\n",
        "        return x1, x2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIZLEMF_jSnk"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7NMy1t2cqX6",
        "outputId": "ad250dc5-5397-4b85-feef-376a76f0fb30"
      },
      "outputs": [],
      "source": [
        "# Set directory\n",
        "BASE_DIR = Path(f\"/content/drive/MyDrive/RedHack\")\n",
        "\n",
        "DATA_DIR = BASE_DIR.joinpath(\"data\")\n",
        "\n",
        "FILE_RESP = \"web_response.csv\"\n",
        "FILE_THR = \"throughput.csv\"\n",
        "FILE_ERROR = \"error.csv\"\n",
        "FILE_APDEX = \"apdex.csv\"\n",
        "\n",
        "RESP_DATA = DATA_DIR.joinpath(FILE_RESP)\n",
        "THR_DATA = DATA_DIR.joinpath(FILE_THR)\n",
        "ERROR_DATA = DATA_DIR.joinpath(FILE_ERROR)\n",
        "APDEX_DATA = DATA_DIR.joinpath(FILE_APDEX)\n",
        "\n",
        "web_response = pd.read_csv(RESP_DATA, header=0, sep=',', index_col=0)\n",
        "throughput = pd.read_csv(THR_DATA, header=0, sep=',', index_col=0)\n",
        "error = pd.read_csv(ERROR_DATA, header=0, sep=',', index_col=0)\n",
        "apdex = pd.read_csv(APDEX_DATA, header=0, sep=',', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug9xVTf-0-rJ",
        "outputId": "f9f551e8-46b8-4bbd-b17a-3f40eaac8465"
      },
      "outputs": [],
      "source": [
        "print(f\"web_response: {web_response.shape}\")\n",
        "print(f\"throughput: {throughput.shape}\")\n",
        "print(f\"error: {error.shape}\")\n",
        "print(f\"apdex: {apdex.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNSWeSPu1ah0"
      },
      "outputs": [],
      "source": [
        "web_response.rename(columns={\"point\": \"timestamp\"}, inplace=True)\n",
        "throughput.rename(columns={\"point\": \"timestamp\", \"sum_call_count\": \"throughput\"}, inplace=True)\n",
        "error.rename(columns={\"point\": \"timestamp\", \"ratio\": \"error\"}, inplace=True)\n",
        "apdex.rename(columns={\"time\": \"timestamp\", \" \": \"apdex\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ_rcpt31WYW"
      },
      "outputs": [],
      "source": [
        "# Multivariate task\n",
        "# Concat all data\n",
        "\n",
        "ts_df = pd.merge(web_response, throughput, on=\"timestamp\")\n",
        "ts_df = pd.merge(ts_df, error, on=\"timestamp\")\n",
        "ts_df = pd.merge(ts_df, apdex, on=\"timestamp\")\n",
        "\n",
        "timestamp = ts_df[\"timestamp\"]\n",
        "ts_df.drop(\"timestamp\", inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eudV-143Q2Mp"
      },
      "outputs": [],
      "source": [
        "# Remove seasonality\n",
        "\n",
        "# from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# result = seasonal_decompose(ts_df['web_response'], model='additive', period=1440)  # Period is the number of minutes in a day\n",
        "# ts_df['web_response'] = ts_df['web_response'] - result.seasonal\n",
        "\n",
        "# result = seasonal_decompose(ts_df['throughput'], model='additive', period=1440)  # Period is the number of minutes in a day\n",
        "# ts_df['throughput'] = ts_df['throughput'] - result.seasonal\n",
        "\n",
        "# result = seasonal_decompose(ts_df['error'], model='additive', period=1440)  # Period is the number of minutes in a day\n",
        "# ts_df['error'] = ts_df['error'] - result.seasonal\n",
        "\n",
        "# result = seasonal_decompose(ts_df['apdex'], model='additive', period=1440)  # Period is the number of minutes in a day\n",
        "# ts_df['apdex'] = ts_df['apdex'] - result.seasonal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A47OWrP03WaG",
        "outputId": "e96c4e62-8ec6-444d-ce6d-9a2036acad67"
      },
      "outputs": [],
      "source": [
        "ts_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rk2sTsNE5itz"
      },
      "outputs": [],
      "source": [
        "def min_max_scaling(df, phi=0.05):\n",
        "    df_normalized = df.copy()\n",
        "    for column in df.columns:\n",
        "        min_val = df[column].min()\n",
        "        max_val = df[column].max()\n",
        "        df_normalized[column] = (df[column] - min_val) / (max_val - min_val + phi)\n",
        "    return df_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5MJYbg96NFS"
      },
      "outputs": [],
      "source": [
        "def plot_columns(df):\n",
        "    num_cols = df.shape[1]\n",
        "    fig, axes = plt.subplots(num_cols, 1, figsize=(15, 5*num_cols))\n",
        "\n",
        "    for i, column in enumerate(df.columns):\n",
        "        ax = axes[i] if num_cols > 1 else axes\n",
        "        ax.plot(df[column])\n",
        "        ax.set_title(column)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVPMhZvCkQAG"
      },
      "outputs": [],
      "source": [
        "# Data Prepocessing\n",
        "# X_train, X_test = ts_df[:int(ts_df.shape[0]*0.7)], ts_df[int(ts_df.shape[0]*0.7):]\n",
        "\n",
        "# X_train_norm = min_max_scaling(X_train, phi=0.0)\n",
        "# X_test_norm = min_max_scaling(X_test, phi=0.0)\n",
        "\n",
        "# X_train_norm = [normalize(val, X_train[\"web_response\"].min(), X_train[\"web_response\"].max()) for val in X_train[\"web_response\"]]\n",
        "# X_test_norm = [normalize(val, X_test[\"web_response\"].min(), X_test[\"web_response\"].max()) for val in X_test[\"web_response\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmzUl8w3J5WY"
      },
      "outputs": [],
      "source": [
        "X_train_norm = min_max_scaling(ts_df, phi=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rqzevRGt502j",
        "outputId": "821da667-6750-4234-d760-2ac987bc3fdb"
      },
      "outputs": [],
      "source": [
        "plot_columns(X_train_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAO6cq45BuQQ"
      },
      "outputs": [],
      "source": [
        "X_train_norm.columns = [i for i in range(X_train_norm.shape[1])]\n",
        "# X_test_norm.columns = [i for i in range(X_test_norm.shape[1])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c40bNdXXm5pv"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(np.array(X_train_norm), batch_size=len(X_train_norm))\n",
        "# test_loader = DataLoader(np.array(X_test_norm), batch_size=len(X_test_norm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C7M7xcivzqc"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Naf8vmJRHzzg"
      },
      "outputs": [],
      "source": [
        "class color:\n",
        "    HEADER = '\\033[95m'\n",
        "    BLUE = '\\033[94m'\n",
        "    GREEN = '\\033[92m'\n",
        "    RED = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECrA7lZ6AJFh"
      },
      "outputs": [],
      "source": [
        "def convert_to_windows(data, model):\n",
        "    windows = []\n",
        "    w_size = model.n_window\n",
        "    for i, g in enumerate(data):\n",
        "        if i >= w_size:\n",
        "            w = data[i-w_size:i]\n",
        "        else:\n",
        "            w = torch.cat([data[0].repeat(w_size-i, 1), data[0:i]])\n",
        "        windows.append(w)\n",
        "    return torch.stack(windows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37_Z6hX5DUKw"
      },
      "outputs": [],
      "source": [
        "def backprop(epoch, model, data, dataO, optimizer, scheduler, training = True):\n",
        "    # l = nn.MSELoss(reduction = 'mean' if training else 'none')\n",
        "    feats = dataO.shape[1]\n",
        "    l = nn.MSELoss(reduction = 'none')\n",
        "    data_x = torch.DoubleTensor(data)\n",
        "    dataset = TensorDataset(data_x, data_x)\n",
        "    bs = model.batch if training else len(data)\n",
        "    dataloader = DataLoader(dataset, batch_size=bs)\n",
        "    n = epoch + 1; w_size = model.n_window\n",
        "    l1s, l2s = [], []\n",
        "    if training:\n",
        "        for d, _ in dataloader:\n",
        "            local_bs = d.shape[0]\n",
        "            window = d.permute(1, 0, 2)\n",
        "            elem = window[-1, :, :].view(1, local_bs, feats)\n",
        "            z = model(window, elem)\n",
        "            l1 = l(z, elem) if not isinstance(z, tuple) else (1 / n) * l(z[0], elem) + (1 - 1/n) * l(z[1], elem)\n",
        "            if isinstance(z, tuple):\n",
        "                z = z[1]\n",
        "            l1s.append(torch.mean(l1).item())\n",
        "            loss = torch.mean(l1)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward(retain_graph=True)\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "        tqdm.write(f'Epoch {epoch},\\tL1 = {np.mean(l1s)}')\n",
        "        return np.mean(l1s), optimizer.param_groups[0]['lr']\n",
        "    else:\n",
        "        for d, _ in dataloader:\n",
        "            window = d.permute(1, 0, 2)\n",
        "            elem = window[-1, :, :].view(1, bs, feats)\n",
        "            z = model(window, elem)\n",
        "            if isinstance(z, tuple):\n",
        "                z = z[1]\n",
        "        loss = l(z, elem)[0]\n",
        "        return loss.detach().numpy(), z.detach().numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfcsW4I_H5Ge"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, scheduler, epoch, accuracy_list, num_exp):\n",
        "\tfolder = f'{BASE_DIR}/checkpoints/TranAD_TS/Experiment_{num_exp}'\n",
        "\tos.makedirs(folder, exist_ok=True)\n",
        "\tfile_path = f'{folder}/model.ckpt'\n",
        "\ttorch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "        'accuracy_list': accuracy_list}, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3pF1u0QIjq8"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(accuracy_list, folder, num_exp):\n",
        "\tos.makedirs(f'{BASE_DIR}/plots/{folder}/Experiment_{num_exp}', exist_ok=True)\n",
        "\ttrainAcc = [i[0] for i in accuracy_list]\n",
        "\tlrs = [i[1] for i in accuracy_list]\n",
        "\tplt.xlabel('Epochs')\n",
        "\tplt.ylabel('Average Training Loss')\n",
        "\tplt.plot(range(len(trainAcc)), trainAcc, label='Average Training Loss', linewidth=1, linestyle='-', marker='.')\n",
        "\tplt.twinx()\n",
        "\tplt.plot(range(len(lrs)), lrs, label='Learning Rate', color='r', linewidth=1, linestyle='--', marker='.')\n",
        "\tplt.savefig(f'{BASE_DIR}/plots/{folder}/Experiment_{num_exp}/training-graph.pdf')\n",
        "\tplt.clf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16XFrxDTUKpa"
      },
      "outputs": [],
      "source": [
        "def smooth(y, box_pts=1):\n",
        "    box = np.ones(box_pts)/box_pts\n",
        "    y_smooth = np.convolve(y, box, mode='same')\n",
        "    return y_smooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9g8fRQdT5dm"
      },
      "outputs": [],
      "source": [
        "def plotter(name, y_true, y_pred, ascore, labels, num_exp):\n",
        "    y_true = torch.roll(y_true, 1, 0)\n",
        "    os.makedirs(os.path.join(f'plots/', f'{name}/Experiment_{num_exp}'), exist_ok=True)\n",
        "    pdf = PdfPages(f'{BASE_DIR}/plots/{name}/Experiment_{num_exp}/output.pdf')\n",
        "    for dim in range(y_true.shape[1]):\n",
        "        y_t, y_p, l, a_s = y_true[:, dim], y_pred[:, dim], labels[dim], ascore[:, dim]\n",
        "        fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
        "        ax1.set_ylabel('Value')\n",
        "        ax1.set_title(f'Dimension = {dim}')\n",
        "        # if dim == 0: np.save(f'true{dim}.npy', y_t); np.save(f'pred{dim}.npy', y_p); np.save(f'ascore{dim}.npy', a_s)\n",
        "        ax1.plot(smooth(y_t), linewidth=0.2, label='True')\n",
        "        ax1.plot(smooth(y_p), '-', alpha=0.6, linewidth=0.3, label='Predicted')\n",
        "        ax3 = ax1.twinx()\n",
        "        ax3.plot(l, '--', linewidth=0.3, alpha=0.5)\n",
        "        ax3.fill_between(np.arange(len(l)), l, color='blue', alpha=0.3)\n",
        "        if dim == 0: ax1.legend(ncol=2, bbox_to_anchor=(0.6, 1.02))\n",
        "        ax2.plot(smooth(a_s), linewidth=0.2, color='g')\n",
        "        ax2.set_xlabel('Timestamp')\n",
        "        ax2.set_ylabel('Anomaly Score')\n",
        "        pdf.savefig(fig)\n",
        "        plt.close()\n",
        "    pdf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFF8iEwcn8Rk"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 20\n",
        "NUM_LABELS = X_train_norm.shape[1]\n",
        "LEARNING_RATE = 10e-5\n",
        "WINDOW_SIZE = 20\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De84YzMO9OxK"
      },
      "outputs": [],
      "source": [
        "model = TranAD(\n",
        "    feats=NUM_LABELS,\n",
        "    lr=LEARNING_RATE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    window_size=WINDOW_SIZE\n",
        ")\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=model.lr, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 5, 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fE-2SKn3_GTj"
      },
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "# trainD, testD = next(iter(train_loader)), next(iter(test_loader))\n",
        "# trainO, testO = trainD, testD\n",
        "\n",
        "# trainD, testD = convert_to_windows(trainD, model), convert_to_windows(testD, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hg1CMTE1KYt7"
      },
      "outputs": [],
      "source": [
        "trainD = next(iter(train_loader))\n",
        "trainO = trainD\n",
        "\n",
        "trainD = convert_to_windows(trainD, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "jTD7quzRCa0r",
        "outputId": "be955ca9-3505-4275-db34-4c6352355e6b"
      },
      "outputs": [],
      "source": [
        "NUM_EXP = 2\n",
        "accuracy_list = []\n",
        "start = time()\n",
        "for e in tqdm(list(range(NUM_EPOCHS))):\n",
        "\tlossT, lr = backprop(e, model, trainD, trainO, optimizer, scheduler)\n",
        "\taccuracy_list.append((lossT, lr))\n",
        "\n",
        "print(color.BOLD+'Training time: '+\"{:10.4f}\".format(time()- start)+' s'+color.ENDC)\n",
        "save_model(model, optimizer, scheduler, e, accuracy_list, num_exp=NUM_EXP)\n",
        "plot_accuracies(accuracy_list, f'TranAD_TS', num_exp=NUM_EXP)\n",
        "# Save params\n",
        "params_dict = {\n",
        "\t   \"batch_size\": int(BATCH_SIZE),\n",
        "\t   \"epochs\": int(NUM_EPOCHS),\n",
        "\t   \"labels\": list(ts_df.columns),\n",
        "\t   \"lr\": int(LEARNING_RATE),\n",
        "\t   \"window_size\": int(WINDOW_SIZE)\n",
        "}\n",
        "\n",
        "\n",
        "import json\n",
        "os.makedirs(f'plots/TranAD/Experiment_{NUM_EXP}', exist_ok=True)\n",
        "with open(f'{BASE_DIR}/plots/TranAD_TS/Experiment_{NUM_EXP}/params.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(params_dict, f, ensure_ascii=False, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcO_p8UASZEL"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = TranAD(\n",
        "    feats=NUM_LABELS,\n",
        "    lr=LEARNING_RATE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    window_size=WINDOW_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBeuguMJIl8g",
        "outputId": "d7b3fd1e-3866-4388-b8b9-076429a54599"
      },
      "outputs": [],
      "source": [
        "torch.zero_grad = True\n",
        "model.eval()\n",
        "print(f'{color.HEADER}Testing TranAD on TS{color.ENDC}')\n",
        "# loss, y_pred = backprop(0, model, testD, testO, optimizer, scheduler, training=False)\n",
        "loss, y_pred = backprop(0, model, trainD, trainO, optimizer, scheduler, training=False)\n",
        "\n",
        "# testO = torch.roll(testO, 1, 0)\n",
        "trainO = torch.roll(trainO, 1, 0)\n",
        "# plotter(f'TranAD_TS', testO, y_pred, loss, X_test.columns)\n",
        "plotter(f'TranAD_TS', trainO, y_pred, loss, ts_df.columns, num_exp=NUM_EXP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ruRx0CJBdf9m",
        "outputId": "8e2b17fd-c6b7-4d7b-ae53-55ae1361a8ef"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LI4eKF3dw8z",
        "outputId": "ea9cd49d-be22-4cfe-8350-55da1ec120fb"
      },
      "outputs": [],
      "source": [
        "q90 = np.quantile(loss, q=0.9)\n",
        "sum(loss >= q90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws6aC5GlexDF"
      },
      "outputs": [],
      "source": [
        "def detect_anomalies( q, anomaly_score, labels):\n",
        "    # False - norm\n",
        "    # True - outlier\n",
        "    q_n = np.quantile(anomaly_score, q=q)\n",
        "    anomaly_arr = anomaly_score >= q_n\n",
        "    return anomaly_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jjjB9DEhwmU"
      },
      "outputs": [],
      "source": [
        "anomaly_arr = detect_anomalies(q=0.9, anomaly_score=loss, labels=ts_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHJs7ukVikku"
      },
      "outputs": [],
      "source": [
        "test_data = trainO.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBtNAV65ikeh"
      },
      "outputs": [],
      "source": [
        "test_df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i-tMzULikQf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLG_hdcbMs0w"
      },
      "outputs": [],
      "source": [
        "# On short win\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IO21uu3fePoq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
