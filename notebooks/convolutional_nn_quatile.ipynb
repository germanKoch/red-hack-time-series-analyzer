{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# save checkpoint\n",
    "# Function to save model checkpoint\n",
    "def save_checkpoint(model, scaler, path='model_checkpoint.pth'):\n",
    "    checkpoint = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'threshold': model.threshold,\n",
    "        'scaler': scaler\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f'Checkpoint saved at epoch')\n",
    "\n",
    "def load_checkpoint(path, model):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.threshold = checkpoint['threshold']\n",
    "    scaler = checkpoint['scaler']\n",
    "    return scaler, model\n",
    "\n",
    "\n",
    "def plot_time_series(time_series, prediction, title='Time Series with Quantiles'):\n",
    "    \"\"\"\n",
    "    Plots the real time series and quantiles predicted by the autoencoder.\n",
    "\n",
    "    Parameters:\n",
    "    - time_series: numpy array of the actual time series values.\n",
    "    - quantiles: numpy array of shape (n_samples, n_quantiles, seq_length) containing the predicted quantiles.\n",
    "    - seq_length: int, length of the sequence used for the predictions.\n",
    "    - title: str, title of the plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot the actual time series\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.plot(time_series, label='Actual Time Series', color='blue')\n",
    "    plt.plot(prediction, label='Predition', color='orange')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_time_series_with_errors_area(time_series, prediction, error_low, error_high):\n",
    "    \"\"\"\n",
    "    Plots the real time series and quantiles predicted by the autoencoder.\n",
    "\n",
    "    Parameters:\n",
    "    - time_series: numpy array of the actual time series values.\n",
    "    - quantiles: numpy array of shape (n_samples, n_quantiles, seq_length) containing the predicted quantiles.\n",
    "    - seq_length: int, length of the sequence used for the predictions.\n",
    "    - title: str, title of the plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot the actual time series\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.plot(time_series, label='Actual Time Series', color='blue')\n",
    "    plt.plot(prediction, label='Predition', color='orange')\n",
    "    plt.fill_between(np.arange(0, len(time_series)), error_low, error_high, alpha=0.3)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_time_series_with_quantiles(time_series, quantiles, seq_length, title='Time Series with Quantiles'):\n",
    "    \"\"\"\n",
    "    Plots the real time series and quantiles predicted by the autoencoder.\n",
    "\n",
    "    Parameters:\n",
    "    - time_series: numpy array of the actual time series values.\n",
    "    - quantiles: numpy array of shape (n_samples, n_quantiles, seq_length) containing the predicted quantiles.\n",
    "    - seq_length: int, length of the sequence used for the predictions.\n",
    "    - title: str, title of the plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot the actual time series\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.plot(time_series, label='Actual Time Series', color='blue')\n",
    "    \n",
    "    # Plot the quantiles\n",
    "    for index in range(0, len(quantiles)//2):\n",
    "        print(quantiles[index])\n",
    "        print(quantiles[len(quantiles)-index-1])\n",
    "        plt.fill_between(np.arange(0, len(time_series)), \n",
    "                         quantiles[index], quantiles[len(quantiles)-index-1], label=f'Quantile {index+1}', alpha=0.3)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaler(values):\n",
    "    values = values.reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(values)\n",
    "    return scaler\n",
    "\n",
    "\n",
    "def create_dataloader(values, scaler, seq_length, train_ratio):\n",
    "    values = values.reshape(-1, 1)\n",
    "\n",
    "    # Normalize the data\n",
    "    values_scaled = scaler.transform(values)\n",
    "\n",
    "    # Create sequences\n",
    "    def create_sequences(data, seq_length):\n",
    "        sequences = []\n",
    "        for i in range(len(data) - seq_length):\n",
    "            sequences.append(data[i:i + seq_length])\n",
    "        return np.array(sequences)\n",
    "\n",
    "    X = create_sequences(values_scaled, seq_length)\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    dataset = TensorDataset(X, X)\n",
    "\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "    return dataset, train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "throughput = pd.read_csv('./../data/throughput.csv')\n",
    "web_response = pd.read_csv('./../data/web_response.csv')\n",
    "apdex = pd.read_csv('./../data/apdex.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comvolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(pl.LightningModule):\n",
    "    def __init__(self, loss, hidden_size, seq_len):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, 3, padding=1),  # Output: [batch_size, 32, seq_len]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2),       # Output: [batch_size, 32, seq_len//2]\n",
    "            nn.Conv1d(32, 16, 3, padding=1), # Output: [batch_size, 16, seq_len//2]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2),       # Output: [batch_size, 16, seq_len//4]\n",
    "            nn.Conv1d(16, 8, 3, padding=1),  # Output: [batch_size, 8, seq_len//4]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2)        # Output: [batch_size, 8, seq_len//8]\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(8, 16, 4, stride=2, padding=1), # Output: [batch_size, 16, seq_len//4]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(16, 32, 4, stride=2, padding=1), # Output: [batch_size, 32, seq_len//2]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(32, 1, 4, stride=2, padding=1),  # Output: [batch_size, 1, seq_len]\n",
    "        )\n",
    "        self.loss = loss\n",
    "        self.seq_len = seq_len\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # [batch_size, seq_len, 1] -> [batch_size, 1, seq_len]\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        decoded = decoded.permute(0, 2, 1)  # [batch_size, 1, seq_len] -> [batch_size, seq_len, 1]\n",
    "        return decoded\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, _ = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss(outputs, inputs.permute(0, 2, 1))\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        return optimizer\n",
    "    \n",
    "    # Function to evaluate model on validation set\n",
    "    def evaluate_threshhold(self, val_loader, percentile):\n",
    "        self.eval()  # Set model to evaluation mode\n",
    "        val_loss = []\n",
    "        criterion = nn.L1Loss()\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            for x, y in val_loader:\n",
    "                y_hat = self(x)\n",
    "                loss = criterion(y_hat, y)\n",
    "                val_loss.append(loss.item())\n",
    "        THRESHOLD = np.percentile(val_loss, percentile)\n",
    "        self.threshold = THRESHOLD\n",
    "        return THRESHOLD\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = get_scaler(throughput['sum_call_count'].values)\n",
    "dataset, train_dataloader, val_dataloader = create_dataloader(throughput['sum_call_count'].values, scaler, 64, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\courses\\MLsimulator\\venv\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:653: Checkpoint directory D:\\projects\\code\\red-hack-time-series-analyzer\\notebooks exists and is not empty.\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 2.1 K \n",
      "1 | decoder | Sequential | 2.7 K \n",
      "2 | loss    | L1Loss     | 0     \n",
      "---------------------------------------\n",
      "4.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.8 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\courses\\MLsimulator\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "d:\\courses\\MLsimulator\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "d:\\courses\\MLsimulator\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   1%|          | 6/1081 [00:00<00:21, 49.89it/s, v_num=59, train_loss_step=0.886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\courses\\MLsimulator\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:101: UserWarning: Using a target size (torch.Size([32, 1, 64])) that is different to the input size (torch.Size([32, 64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  46%|████▋     | 500/1081 [00:08<00:09, 58.85it/s, v_num=59, train_loss_step=0.251]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 8/1081 [00:00<00:17, 59.76it/s, v_num=59, train_loss_step=0.229, val_loss_step=0.0899, val_loss_epoch=0.168, train_loss_epoch=0.264]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\courses\\MLsimulator\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:101: UserWarning: Using a target size (torch.Size([6, 1, 64])) that is different to the input size (torch.Size([6, 64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1081/1081 [00:27<00:00, 40.01it/s, v_num=59, train_loss_step=0.171, val_loss_step=0.168, val_loss_epoch=0.162, train_loss_epoch=0.232]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1081/1081 [00:27<00:00, 40.00it/s, v_num=59, train_loss_step=0.171, val_loss_step=0.168, val_loss_epoch=0.162, train_loss_epoch=0.232]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = ConvAutoencoder(hidden_size=128, loss=nn.L1Loss(), seq_len=64)\n",
    "# Initialize EarlyStopping callback\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=10,          # Number of epochs with no improvement to stop training\n",
    "    verbose=True,        # Enable verbose mode\n",
    "    mode='min'           # Mode 'min' to stop when the metric stops decreasing\n",
    ")\n",
    "# Initialize ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',      # Metric to monitor\n",
    "    dirpath='checkpoints/',  # Directory to save checkpoints\n",
    "    filename='best-checkpoint',  # Filename for the best checkpoint\n",
    "    save_top_k=1,            # Save only the best checkpoint\n",
    "    mode='min',              # Mode 'min' to save the checkpoint with the lowest 'val_loss'\n",
    "    save_last=True,          # Save the final model\n",
    "    verbose=True\n",
    ")\n",
    "checkpoint_callback = ModelCheckpoint('./')\n",
    "trainer = pl.Trainer(max_epochs=2, logger=True, log_every_n_steps=1, val_check_interval=500, callbacks=[early_stop_callback, checkpoint_callback])\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3898. , 3917.5, 3993. , ..., 2429. , 2373.5, 1170. ])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(pl.LightningModule):\n",
    "    def __init__(self, input_dim, seq_len, hidden_dim=128, dropout_rate=0.2, loss=nn.L1Loss()):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.repeat_vector = lambda x: x.unsqueeze(1).repeat(1, self.seq_len, 1)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.time_distributed_dense = nn.Linear(hidden_dim, input_dim)\n",
    "        self.loss = loss\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM layer\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # RepeatVector\n",
    "        x = self.repeat_vector(x[:, -1, :])\n",
    "        \n",
    "        # LSTM layer\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # TimeDistributed Dense layer\n",
    "        x = self.time_distributed_dense(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        y_pred = self(x)\n",
    "        loss = self.loss(y_pred, x)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
    "        return optimizer\n",
    "    \n",
    "    # Function to evaluate model on validation set\n",
    "    def evaluate_threshhold(self, val_loader, percentile):\n",
    "        self.eval()  # Set model to evaluation mode\n",
    "        val_loss = []\n",
    "        criterion = nn.L1Loss()\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            for x, y in val_loader:\n",
    "                y_hat = self(x)\n",
    "                loss = criterion(y_hat, y)\n",
    "                val_loss.append(loss.item())\n",
    "        THRESHOLD = np.percentile(val_loss, percentile)\n",
    "        self.threshold = THRESHOLD\n",
    "        return THRESHOLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = get_scaler(throughput['sum_call_count'].values)\n",
    "dataset, train_dataloader, val_dataloader = create_dataloader(throughput['sum_call_count'].values, scaler, 20, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                   | Type    | Params\n",
      "---------------------------------------------------\n",
      "0 | lstm1                  | LSTM    | 67.1 K\n",
      "1 | dropout1               | Dropout | 0     \n",
      "2 | lstm2                  | LSTM    | 132 K \n",
      "3 | dropout2               | Dropout | 0     \n",
      "4 | time_distributed_dense | Linear  | 129   \n",
      "5 | loss                   | L1Loss  | 0     \n",
      "---------------------------------------------------\n",
      "199 K     Trainable params\n",
      "0         Non-trainable params\n",
      "199 K     Total params\n",
      "0.797     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 87.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\courses\\MLsimulator\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   9%|▉         | 100/1082 [00:02<00:24, 40.56it/s, v_num=47, train_loss_step=0.237]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  18%|█▊        | 200/1082 [00:08<00:36, 24.18it/s, v_num=47, train_loss_step=0.168, val_loss_step=0.268, val_loss_epoch=0.259]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.078 >= min_delta = 0.0. New best score: 0.181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  28%|██▊       | 300/1082 [00:14<00:36, 21.18it/s, v_num=47, train_loss_step=0.172, val_loss_step=0.137, val_loss_epoch=0.181]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.022 >= min_delta = 0.0. New best score: 0.159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  37%|███▋      | 400/1082 [00:20<00:34, 19.82it/s, v_num=47, train_loss_step=0.195, val_loss_step=0.198, val_loss_epoch=0.159]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  46%|████▌     | 500/1082 [00:26<00:31, 18.71it/s, v_num=47, train_loss_step=0.188, val_loss_step=0.110, val_loss_epoch=0.154]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  55%|█████▌    | 600/1082 [00:33<00:26, 18.14it/s, v_num=47, train_loss_step=0.155, val_loss_step=0.165, val_loss_epoch=0.152]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  65%|██████▍   | 700/1082 [00:40<00:21, 17.38it/s, v_num=47, train_loss_step=0.174, val_loss_step=0.0837, val_loss_epoch=0.147]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  74%|███████▍  | 800/1082 [00:47<00:16, 16.84it/s, v_num=47, train_loss_step=0.121, val_loss_step=0.134, val_loss_epoch=0.147] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  83%|████████▎ | 900/1082 [00:54<00:10, 16.67it/s, v_num=47, train_loss_step=0.148, val_loss_step=0.128, val_loss_epoch=0.144] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  92%|█████████▏| 1000/1082 [01:01<00:05, 16.30it/s, v_num=47, train_loss_step=0.106, val_loss_step=0.397, val_loss_epoch=0.143]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|▉         | 100/1082 [00:02<00:25, 38.33it/s, v_num=47, train_loss_step=0.136, val_loss_step=0.126, val_loss_epoch=0.142, train_loss_epoch=0.211] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  18%|█▊        | 200/1082 [00:09<00:40, 21.89it/s, v_num=47, train_loss_step=0.199, val_loss_step=0.116, val_loss_epoch=0.140, train_loss_epoch=0.211]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  28%|██▊       | 300/1082 [00:15<00:40, 19.45it/s, v_num=47, train_loss_step=0.185, val_loss_step=0.102, val_loss_epoch=0.139, train_loss_epoch=0.211] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  37%|███▋      | 400/1082 [00:22<00:37, 17.98it/s, v_num=47, train_loss_step=0.105, val_loss_step=0.0912, val_loss_epoch=0.139, train_loss_epoch=0.211] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  46%|████▌     | 500/1082 [00:28<00:33, 17.35it/s, v_num=47, train_loss_step=0.166, val_loss_step=0.138, val_loss_epoch=0.139, train_loss_epoch=0.211] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 1 records. Best score: 0.139. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  46%|████▌     | 500/1082 [00:32<00:38, 15.29it/s, v_num=47, train_loss_step=0.166, val_loss_step=0.121, val_loss_epoch=0.143, train_loss_epoch=0.151]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  46%|████▌     | 500/1082 [00:32<00:38, 15.29it/s, v_num=47, train_loss_step=0.166, val_loss_step=0.121, val_loss_epoch=0.143, train_loss_epoch=0.151]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = LSTMModel(input_dim=1, hidden_dim=128, seq_len=20)\n",
    "# Initialize EarlyStopping callback\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=0,          # Number of epochs with no improvement to stop training\n",
    "    verbose=True,        # Enable verbose mode\n",
    "    mode='min'           # Mode 'min' to stop when the metric stops decreasing\n",
    ")\n",
    "# Initialize ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',      # Metric to monitor\n",
    "    dirpath='checkpoints/',  # Directory to save checkpoints\n",
    "    filename='best-checkpoint',  # Filename for the best checkpoint\n",
    "    save_top_k=1,            # Save only the best checkpoint\n",
    "    mode='min',              # Mode 'min' to save the checkpoint with the lowest 'val_loss'\n",
    "    save_last=True,          # Save the final model\n",
    "    verbose=True\n",
    ")\n",
    "checkpoint_callback = ModelCheckpoint('./')\n",
    "trainer = pl.Trainer(max_epochs=2, logger=True, log_every_n_steps=1, val_check_interval=100, callbacks=[early_stop_callback, checkpoint_callback])\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save checkpoint\n",
    "# Function to save model checkpoint\n",
    "def save_checkpoint(model, path='model_checkpoint.pth'):\n",
    "    checkpoint = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'threshold': model.threshold,\n",
    "        'scaler': scaler\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f'Checkpoint saved at epoch')\n",
    "\n",
    "def load_checkpoint(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model = LSTMModel(input_dim=1, seq_len=60)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.threshold = checkpoint['threshold']\n",
    "    scaler = checkpoint['scaler']\n",
    "    return scaler, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at epoch\n"
     ]
    }
   ],
   "source": [
    "save_checkpoint(model, 'model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, loaded_model = load_checkpoint('model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming x_train and y_train are your data tensors\n",
    "# Example:\n",
    "# x_train = torch.randn(1000, 10, 10)  # 1000 samples, sequence length 10, 10 features each\n",
    "# y_train = torch.randn(1000, 10, 10)  # 1000 samples, sequence length 10, 10 targets each\n",
    "\n",
    "# Define a function to analyze the time series using the model\n",
    "def detect_anomalies(model, time_series, threshold, window_size):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    anomalies = []\n",
    "    windows = []\n",
    "    predicted_values = []\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for i in range(0, len(time_series) - window_size + 1, window_size):\n",
    "            window = time_series[i:i + window_size].unsqueeze(0)  # Add batch dimension\n",
    "            prediction = model(window).squeeze(0)\n",
    "\n",
    "            windows.extend(window.tolist())\n",
    "            predicted_values.extend(prediction.tolist())\n",
    "\n",
    "            # error = torch.abs(prediction - window.squeeze(0))\n",
    "            # for j in range(window_size):\n",
    "            #     if error[j].item() > threshold:\n",
    "            #         anomalies.append(i + j)  # Mark the specific point as an anomaly\n",
    "    return windows, anomalies, predicted_values\n",
    "\n",
    "# Example time series data (replace with your actual data)\n",
    "time_series_data = torch.FloatTensor(scaler.transform(throughput['sum_call_count'].values[0:240].reshape(-1,1)))  # Replace with your actual time series data\n",
    "window_size = 60  # Replace with your actual window size\n",
    "threshold = model.threshold  # Replace with your actual threshold for anomaly detection\n",
    "\n",
    "# Detect anomalies\n",
    "windows, anomalies, predicted_values = detect_anomalies(model, time_series_data, threshold, window_size)\n",
    "\n",
    "# # Plot the time series, predicted values, and mark the anomalies\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(time_series_data.numpy(), label='Time Series')\n",
    "# plt.scatter(anomalies, time_series_data[anomalies].numpy(), color='red', label='Anomalies', marker='x')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('Value')\n",
    "# plt.title('Time Series with Anomalies and Predicted Values')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0034],\n",
       "         [-0.0126],\n",
       "         [-0.0244],\n",
       "         [-0.0327],\n",
       "         [-0.0377],\n",
       "         [-0.0405],\n",
       "         [-0.0422],\n",
       "         [-0.0432],\n",
       "         [-0.0438],\n",
       "         [-0.0442],\n",
       "         [-0.0444],\n",
       "         [-0.0446],\n",
       "         [-0.0446],\n",
       "         [-0.0447],\n",
       "         [-0.0447],\n",
       "         [-0.0448],\n",
       "         [-0.0448],\n",
       "         [-0.0448],\n",
       "         [-0.0448],\n",
       "         [-0.0448]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(time_series_data[0:20].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2258],\n",
       "        [ 0.2419],\n",
       "        [ 0.3043],\n",
       "        [ 0.3030],\n",
       "        [ 0.2402],\n",
       "        [ 0.2249],\n",
       "        [ 0.0977],\n",
       "        [ 0.0179],\n",
       "        [ 0.0622],\n",
       "        [ 0.0374],\n",
       "        [-0.1031],\n",
       "        [-0.1262],\n",
       "        [-0.1139],\n",
       "        [-0.1899],\n",
       "        [-0.2238],\n",
       "        [-0.2750],\n",
       "        [-0.2969],\n",
       "        [-0.3386],\n",
       "        [-0.3601],\n",
       "        [-0.2403]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_data[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.22576750814914703],\n",
       "  [0.24188075959682465],\n",
       "  [0.304267942905426],\n",
       "  [0.3030284643173218],\n",
       "  [0.24022811651229858],\n",
       "  [0.2249411791563034],\n",
       "  [0.09768781810998917],\n",
       "  [0.017947886139154434],\n",
       "  [0.062156036496162415],\n",
       "  [0.03736642003059387],\n",
       "  [-0.10310807824134827],\n",
       "  [-0.12624505162239075],\n",
       "  [-0.11385024338960648],\n",
       "  [-0.18987172842025757],\n",
       "  [-0.22375087440013885],\n",
       "  [-0.274982750415802],\n",
       "  [-0.29688024520874023],\n",
       "  [-0.3386094272136688],\n",
       "  [-0.36009377241134644],\n",
       "  [-0.24027729034423828],\n",
       "  [-0.1539267897605896],\n",
       "  [-0.17541112005710602],\n",
       "  [-0.22292456030845642],\n",
       "  [-0.2406904399394989],\n",
       "  [-0.16053734719753265],\n",
       "  [-0.0696420893073082],\n",
       "  [-0.020476019009947777],\n",
       "  [-0.004362768959254026],\n",
       "  [0.029516372829675674],\n",
       "  [0.09768781810998917],\n",
       "  [0.04934806749224663],\n",
       "  [0.1745356321334839],\n",
       "  [0.1823856681585312],\n",
       "  [-0.003949608653783798],\n",
       "  [0.0010083146626129746],\n",
       "  [0.05224018916487694],\n",
       "  [0.0724850445985794],\n",
       "  [0.04521646350622177],\n",
       "  [-0.04981039837002754],\n",
       "  [-0.1824348419904709],\n",
       "  [-0.25019311904907227],\n",
       "  [-0.2220982313156128],\n",
       "  [-0.21837979555130005],\n",
       "  [-0.24523520469665527],\n",
       "  [-0.21094290912151337],\n",
       "  [-0.3063829243183136],\n",
       "  [-0.41834935545921326],\n",
       "  [-0.42578625679016113],\n",
       "  [-0.3956255614757538],\n",
       "  [-0.38447022438049316],\n",
       "  [-0.4373547434806824],\n",
       "  [-0.5146157145500183],\n",
       "  [-0.565021276473999],\n",
       "  [-0.5691528916358948],\n",
       "  [-0.6096425652503967],\n",
       "  [-0.6608744263648987],\n",
       "  [-0.7191300392150879],\n",
       "  [-0.7654039859771729],\n",
       "  [-0.7885409593582153],\n",
       "  [-0.8153963685035706]],\n",
       " [[-0.7707750797271729],\n",
       "  [-0.7158247828483582],\n",
       "  [-0.7360696196556091],\n",
       "  [-0.7687093019485474],\n",
       "  [-0.7125194668769836],\n",
       "  [-0.6819456219673157],\n",
       "  [-0.7249143123626709],\n",
       "  [-0.7116931676864624],\n",
       "  [-0.6435217261314392],\n",
       "  [-0.6191452741622925],\n",
       "  [-0.6703771352767944],\n",
       "  [-0.7046694159507751],\n",
       "  [-0.7240879535675049],\n",
       "  [-0.6997115015983582],\n",
       "  [-0.7414407134056091],\n",
       "  [-0.8129174113273621],\n",
       "  [-0.8170490264892578],\n",
       "  [-0.8344017863273621],\n",
       "  [-0.8947231769561768],\n",
       "  [-1.0133001804351807],\n",
       "  [-1.0851900577545166],\n",
       "  [-1.0752742290496826],\n",
       "  [-0.9856184124946594],\n",
       "  [-0.9434760808944702],\n",
       "  [-0.9752894043922424],\n",
       "  [-0.9393444657325745],\n",
       "  [-0.9290154576301575],\n",
       "  [-0.9744631052017212],\n",
       "  [-1.0104080438613892],\n",
       "  [-1.0215634107589722],\n",
       "  [-1.0017316341400146],\n",
       "  [-0.9686788320541382],\n",
       "  [-0.9744631052017212],\n",
       "  [-1.0339581966400146],\n",
       "  [-1.0137133598327637],\n",
       "  [-0.890178382396698],\n",
       "  [-0.8277912139892578],\n",
       "  [-0.9000942707061768],\n",
       "  [-0.9951211214065552],\n",
       "  [-1.0054501295089722],\n",
       "  [-0.9409971237182617],\n",
       "  [-0.895549476146698],\n",
       "  [-0.9240575432777405],\n",
       "  [-0.9393444657325745],\n",
       "  [-0.9678525328636169],\n",
       "  [-1.0566819906234741],\n",
       "  [-1.1008901596069336],\n",
       "  [-1.076926827430725],\n",
       "  [-1.0628794431686401],\n",
       "  [-1.0789926052093506],\n",
       "  [-1.1265060901641846],\n",
       "  [-1.170301079750061],\n",
       "  [-1.21574866771698],\n",
       "  [-1.2562384605407715],\n",
       "  [-1.225664496421814],\n",
       "  [-1.175672173500061],\n",
       "  [-1.13931405544281],\n",
       "  [-1.145098328590393],\n",
       "  [-1.1512956619262695],\n",
       "  [-1.1364219188690186]],\n",
       " [[-1.1355955600738525],\n",
       "  [-1.107913851737976],\n",
       "  [-1.098411202430725],\n",
       "  [-1.150469422340393],\n",
       "  [-1.124440312385559],\n",
       "  [-1.132703423500061],\n",
       "  [-1.21037757396698],\n",
       "  [-1.211617112159729],\n",
       "  [-1.22111976146698],\n",
       "  [-1.235993504524231],\n",
       "  [-1.190959095954895],\n",
       "  [-1.1781511306762695],\n",
       "  [-1.20500648021698],\n",
       "  [-1.2029407024383545],\n",
       "  [-1.2091381549835205],\n",
       "  [-1.211203932762146],\n",
       "  [-1.1835222244262695],\n",
       "  [-1.20500648021698],\n",
       "  [-1.1731932163238525],\n",
       "  [-1.108740210533142],\n",
       "  [-1.171127438545227],\n",
       "  [-1.2198803424835205],\n",
       "  [-1.2397119998931885],\n",
       "  [-1.227317214012146],\n",
       "  [-1.1583194732666016],\n",
       "  [-1.1620378494262695],\n",
       "  [-1.19963538646698],\n",
       "  [-1.2041802406311035],\n",
       "  [-1.2702858448028564],\n",
       "  [-1.3223440647125244],\n",
       "  [-1.3264756202697754],\n",
       "  [-1.3128414154052734],\n",
       "  [-1.2752437591552734],\n",
       "  [-1.277309536933899],\n",
       "  [-1.304991364479065],\n",
       "  [-1.3475468158721924],\n",
       "  [-1.3682048320770264],\n",
       "  [-1.3483731746673584],\n",
       "  [-1.309122920036316],\n",
       "  [-1.293835997581482],\n",
       "  [-1.323996663093567],\n",
       "  [-1.3074703216552734],\n",
       "  [-1.2917702198028564],\n",
       "  [-1.314907193183899],\n",
       "  [-1.3525047302246094],\n",
       "  [-1.3892760276794434],\n",
       "  [-1.3768812417984009],\n",
       "  [-1.3570494651794434],\n",
       "  [-1.4045629501342773],\n",
       "  [-1.4628185033798218],\n",
       "  [-1.4838896989822388],\n",
       "  [-1.5140503644943237],\n",
       "  [-1.5219004154205322],\n",
       "  [-1.5152899026870728],\n",
       "  [-1.5247925519943237],\n",
       "  [-1.5173556804656982],\n",
       "  [-1.4871950149536133],\n",
       "  [-1.4516632556915283],\n",
       "  [-1.4405078887939453],\n",
       "  [-1.4380289316177368]],\n",
       " [[-1.4487711191177368],\n",
       "  [-1.4652974605560303],\n",
       "  [-1.4619922637939453],\n",
       "  [-1.4194366931915283],\n",
       "  [-1.4202630519866943],\n",
       "  [-1.4809975624084473],\n",
       "  [-1.5314031839370728],\n",
       "  [-1.5442111492156982],\n",
       "  [-1.5256189107894897],\n",
       "  [-1.5082662105560303],\n",
       "  [-1.4867818355560303],\n",
       "  [-1.4681895971298218],\n",
       "  [-1.4644712209701538],\n",
       "  [-1.4475315809249878],\n",
       "  [-1.4285262823104858],\n",
       "  [-1.4334841966629028],\n",
       "  [-1.4256341457366943],\n",
       "  [-1.4417473077774048],\n",
       "  [-1.5198346376419067],\n",
       "  [-1.5033082962036133],\n",
       "  [-1.4454658031463623],\n",
       "  [-1.4727343320846558],\n",
       "  [-1.4954582452774048],\n",
       "  [-1.4880213737487793],\n",
       "  [-1.4475315809249878],\n",
       "  [-1.4148919582366943],\n",
       "  [-1.4020839929580688],\n",
       "  [-1.4231551885604858],\n",
       "  [-1.4388552904129028],\n",
       "  [-1.4293525218963623],\n",
       "  [-1.4243946075439453],\n",
       "  [-1.4144787788391113],\n",
       "  [-1.4210894107818604],\n",
       "  [-1.4458789825439453],\n",
       "  [-1.4661238193511963],\n",
       "  [-1.4648844003677368],\n",
       "  [-1.4310052394866943],\n",
       "  [-1.4248077869415283],\n",
       "  [-1.4363763332366943],\n",
       "  [-1.4429868459701538],\n",
       "  [-1.4413342475891113],\n",
       "  [-1.4396815299987793],\n",
       "  [-1.4343104362487793],\n",
       "  [-1.4405078887939453],\n",
       "  [-1.4793449640274048],\n",
       "  [-1.4851292371749878],\n",
       "  [-1.4619922637939453],\n",
       "  [-1.4268735647201538],\n",
       "  [-1.4326578378677368],\n",
       "  [-1.4471184015274048],\n",
       "  [-1.4644712209701538],\n",
       "  [-1.4814107418060303],\n",
       "  [-1.4524894952774048],\n",
       "  [-1.4557948112487793],\n",
       "  [-1.4756264686584473],\n",
       "  [-1.5099188089370728],\n",
       "  [-1.5756113529205322],\n",
       "  [-1.6065982580184937],\n",
       "  [-1.6111431121826172],\n",
       "  [-1.6078377962112427]]]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
